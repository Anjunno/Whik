import json
import os
import boto3
import logging
import requests
import base64
import re
from typing import List, Dict, Any
from googleapiclient.discovery import build # Google Custom Search API Client

# --- í´ë¼ì´ì–¸íŠ¸ ë° í™˜ê²½ ë³€ìˆ˜ ì´ˆê¸°í™” ---
logger = logging.getLogger()
logger.setLevel(logging.INFO)

BEDROCK_REGION = os.environ.get("BEDROCK_REGION", 'us-east-1')
bedrock_runtime = boto3.client(
    service_name='bedrock-runtime', 
    region_name=BEDROCK_REGION
)

# [í•„ìˆ˜ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ]
SEARCH_API_KEY = os.environ.get("GOOGLE_SEARCH_API_KEY")
SEARCH_CX_ID = os.environ.get("GOOGLE_SEARCH_CX_ID")

if not all([SEARCH_API_KEY, SEARCH_CX_ID]):
    logger.error("!!! CRITICAL: Google Search API í™˜ê²½ ë³€ìˆ˜ê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.")
    raise EnvironmentError("Missing required environment variables for Google Search/VLM.")


def generate_search_query(script: Dict) -> str:
    """ 
    AI ëŒ€ë³¸ì—ì„œ ì‘í’ˆëª…, ìºë¦­í„°, ëŒ€ì‚¬ë¥¼ ì¡°í•©í•˜ì—¬ ìµœì ì˜ ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. 
    (í•œêµ­ì–´ ì œëª©ì´ ìˆë‹¤ë©´ ìµœìš°ì„ ìœ¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.)
    """
    title_orig = script.get('source_title', '')      
    title_kr = script.get('source_title_kr', '') # L2ì—ì„œ ë„˜ì–´ì˜¨ í•œêµ­ì–´ ì œëª©
    character = script.get('character_name', '') 
    scene_prompt = script.get('scene_prompt', '')
    
    # 1. [ìµœìš°ì„ ] í•œêµ­ì–´ ì œëª© + ìºë¦­í„° ì¡°í•© (í•œêµ­ì¸ ì¸ì§€ë„ ë° ê²€ìƒ‰ íš¨ìœ¨ ê·¹ëŒ€í™”)
    if title_kr and character:
        return f"{title_kr} {character} ìŠ¤í‹¸ì»· (screenshot)" 

    # 2. [ì°¨ì„ ] ì›ë³¸ ì œëª© + ìºë¦­í„° ì¡°í•©
    if title_orig and character:
        return f"{title_orig} {character} movie screenshot"
    
    # 3. [ì°¨ì„ ] ê°€ì¥ ì˜ ì•Œë ¤ì§„ ì œëª©ë§Œ ì‚¬ìš©
    known_title = title_kr or title_orig
    if known_title:
        return f"{known_title} ì˜í™” ì¥ë©´"
        
    # 4. [ìµœí›„ì˜ ìˆ˜ë‹¨] (Fallback)
    if scene_prompt:
        return f"{scene_prompt[:100]}, cinematic photo"
        
    return "cinematic movie close-up shot"


def search_images_from_google(query: str) -> List[str]:
    """ 
    Google Custom Search APIë¥¼ í˜¸ì¶œí•˜ì—¬ 10ê°œë¥¼ ê°€ì ¸ì˜¨ ë’¤, ìœ íš¨í•œ HTTPS ë§í¬ ìƒìœ„ 5ê°œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    try:
        service = build("customsearch", "v1", developerKey=SEARCH_API_KEY)
        
        # ë„‰ë„‰í•˜ê²Œ 10ê°œ ìš”ì²­
        res = service.cse().list(
            q=query,
            cx=SEARCH_CX_ID,
            searchType='image', 
            num=10, 
            safe='off' 
        ).execute()
        
        raw_items = res.get('items', [])
        
        # [ë””ë²„ê¹…] ì „ì²´ ê²€ìƒ‰ ê²°ê³¼ ë¡œê·¸ ì¶œë ¥
        all_links = [item.get('link', 'N/A') for item in raw_items]
        logger.info(f"ğŸ” Google Raw Search Results ({len(all_links)}): {json.dumps(all_links, indent=2)}")

        valid_urls = []
        # í•„í„°ë§ ë¡œì§: https/httpë¡œ ì‹œì‘í•˜ëŠ” ê²ƒë§Œ ìˆ˜ì§‘
        for item in raw_items:
            link = item.get('link', '')
            if link.startswith('https://') or link.startswith('http://'):
                valid_urls.append(link)
                
            if len(valid_urls) >= 5:
                break
        
        logger.info(f"âœ… Filtered Valid URLs ({len(valid_urls)}): {json.dumps(valid_urls, indent=2)}")
        
        return valid_urls
        
    except Exception as e:
        logger.error(f"Google Search API Fail: {e}")
        return []


def download_and_encode_image(url: str) -> str:
    """ URLì—ì„œ ì´ë¯¸ì§€ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ê³  Base64 ë¬¸ìì—´ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤. """
    try:
        # íƒ€ì„ì•„ì›ƒì„ 3ì´ˆë¡œ ì§§ê²Œ ì„¤ì •
        response = requests.get(url, timeout=3)
        response.raise_for_status() # HTTP ì˜¤ë¥˜ ë°œìƒ ì‹œ ì˜ˆì™¸ ë°œìƒ
        return base64.b64encode(response.content).decode('utf-8')
    except Exception as e:
        logger.warning(f"ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ ({url}): {e}")
        return ""


def select_best_image_from_vlm(job_context: Dict, candidate_urls: List[str]) -> str:
    """ Claude 3 Haiku VLMì„ í˜¸ì¶œí•˜ì—¬ ìµœì ì˜ ì´ë¯¸ì§€ 1ê°œ ì„ ì • """
    
    # [L2ì—ì„œ ë„˜ì–´ì˜¨ ìƒì„¸ ì •ë³´ ì¶”ì¶œ]
    script_data = job_context['script']
    scene_prompt = script_data.get('scene_prompt', 'Cinematic shot')
    character_name = script_data.get('character_name', 'main character')
    emotion_tag = script_data.get('emotion_tag', 'neutral')
    
    # 1. ë‹¤ìš´ë¡œë“œ & ì¸ì½”ë”©
    base64_list = []
    working_urls = []
    
    for url in candidate_urls:
        encoded = download_and_encode_image(url)
        if encoded:
            base64_list.append(encoded)
            working_urls.append(url)
    
    if not base64_list:
        logger.error("ë‹¤ìš´ë¡œë“œ ê°€ëŠ¥í•œ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return ""
        
    # 2. VLM í”„ë¡¬í”„íŠ¸ êµ¬ì„± (ë‹¨ì¼ ë©”ì‹œì§€ êµ¬ì¡°)
    content_list = []
    
    for idx, b64 in enumerate(base64_list):
        content_list.append({
            "type": "image", 
            "source": {
                "type": "base64", 
                "media_type": "image/jpeg", 
                "data": b64
            }
        })
        content_list.append({
            "type": "text", 
            "text": f"Image {idx+1}"
        })
    
    # 3. ìµœì¢… ì§ˆë¬¸: VLMì—ê²Œ ê°•ë ¥í•œ ê±°ë¶€ ì¡°ê±´ê³¼ ì„ íƒ ê¸°ì¤€ì„ ë¶€ì—¬
    content_list.append({
        "type": "text", 
        "text": (
            f"\n\nReview the {len(working_urls)} images above. Your goal is to select the BEST single image for video generation. "
            f"**SCENE CONTEXT:** Character: '{character_name}', Scene: '{scene_prompt}', Emotion: '{emotion_tag}'. "
            f"**SELECTION CRITERIA (Strict Priority):** "
            f"1. **Relevance:** Image must clearly show the character '{character_name}' and match the emotion/mood '{emotion_tag}'. "
            f"2. **Quality & Focus:** Must be a high-resolution, clean screenshot with the character's face clearly visible and centrally framed. "
            f"**3. ABSOLUTE REJECTION RULE (Reject if ANY are met):** "
            f" Â  - Contains logos, advertisements, quizzes, overlaid text, or large borders.\n"
            f" Â  - Is a low-quality webcomic, abstract art, or lacks a recognizable character.\n"
            f"Select the best image number (1 to {len(working_urls)}). Respond ONLY with the number."
        )
    })
    
    # ë©”ì‹œì§€ êµ¬ì¡°: User ì—­í•  í•˜ë‚˜ì— ëª¨ë“  ì»¨í…ì¸  ë‹´ê¸°
    messages = [{"role": "user", "content": content_list}]
    
    # 4. VLM í˜¸ì¶œ
    try:
        response = bedrock_runtime.invoke_model(
            modelId='anthropic.claude-3-haiku-20240307-v1:0',
            contentType='application/json',
            accept='application/json',
            body=json.dumps({
                "anthropic_version": "bedrock-2023-05-31", 
                "messages": messages, 
                "max_tokens": 10 
            })
        )
        resp_text = json.loads(response.get('body').read())['content'][0]['text'].strip()
        
        import re
        match = re.search(r'\d+', resp_text)
        idx = int(match.group(0)) if match else 1
        
        selected_url = working_urls[idx-1] if 1 <= idx <= len(working_urls) else working_urls[0]
        logger.info(f"ğŸ† VLM ìµœì¢… ì„ ì • ì´ë¯¸ì§€ (No.{idx}): {selected_url}")
        return selected_url
        
    except Exception as e:
        logger.error(f"VLM Error: {e}")
        return working_urls[0]


# --- ë©”ì¸ í•¸ë“¤ëŸ¬ (SFN Task) ---
def lambda_handler(event: Dict[str, Any], context):
    
    try:
        # SFN Input
        job_details = event
        job_id = job_details['jobId']
        worker_id = job_details.get('workerId', f"{job_id}-single")
        
        logger.info(f"Worker {worker_id}: ì´ë¯¸ì§€ ê²€ìƒ‰ ì‹œì‘.")
        
        # 1. ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±
        search_query = generate_search_query(job_details['script'])
        
        # 2. ì´ë¯¸ì§€ ê²€ìƒ‰ (1ì°¨)
        candidate_urls = search_images_from_google(search_query)

        # 3. ì‹¤íŒ¨ ì‹œ ì¬ì‹œë„ (2ì°¨: ë‹¨ìˆœ ê²€ìƒ‰ì–´)
        if not candidate_urls:
            logger.warning("1ì°¨ ê²€ìƒ‰ ì‹¤íŒ¨. ì‘í’ˆëª… ë˜ëŠ” ë‹¨ìˆœ í‚¤ì›Œë“œë¡œ ì¬ì‹œë„í•©ë‹ˆë‹¤.")
            
            # [ìˆ˜ì •] 2ì°¨ ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„± (Fallback)
            title = job_details['script'].get('source_title', '')
            if title:
                # í•œêµ­ì–´ ì œëª©ì´ ìˆì„ ê²½ìš° í•œêµ­ì–´ ê²€ìƒ‰ì–´ë¡œ ì¬ì‹œë„
                title_kr = job_details['script'].get('source_title_kr', '')
                if title_kr:
                    simple_query = f"{title_kr} ì˜í™” ì¥ë©´"
                else:
                    simple_query = f"{title} movie scene"
            else:
                simple_query = " ".join(job_details['script'].get('scene_prompt', '').split()[:5]) + " cinematic"
            
            logger.info(f"Retry Query: {simple_query}")
            candidate_urls = search_images_from_google(simple_query)
        
        if not candidate_urls:
            logger.error(f"Worker {worker_id}: ì´ë¯¸ì§€ ê²€ìƒ‰ ìµœì¢… ì‹¤íŒ¨.")
            raise Exception("Search API returned no valid image candidates.")

        # 4. VLM ì„ ì •
        best_image_url = select_best_image_from_vlm(job_details, candidate_urls)
            
        # 5. ê²°ê³¼ ë°˜í™˜
        job_details['best_image_url'] = best_image_url
        return job_details

    except Exception as e:
        logger.error(f"L3 Error: {e}", exc_info=True)
        # Step Functionì´ ì˜¤ë¥˜ë¥¼ ê°ì§€í•˜ê³  Fail ìƒíƒœë¡œ ì „í™˜í•˜ë„ë¡ ì˜¤ë¥˜ë¥¼ ì „íŒŒí•©ë‹ˆë‹¤.
        raise e